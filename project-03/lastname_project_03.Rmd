---
title: "Visualizing Text and Distributions"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

# Data Visualization Project 03


In this exercise you will explore methods to visualize text data and practice how to recreate charts that show the distributions of a continuous variable. 


## Part 1: Density Plots

Using the dataset obtained from FSU's [Florida Climate Center](https://climatecenter.fsu.edu/climate-data-access-tools/downloadable-data), for a station at Tampa International Airport (TPA) from 2016 to 2017, attempt to recreate the charts shown below

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
weather_tpa <- read_csv("https://github.com/reisanar/datasets/raw/master/tpa_weather_16_17.csv")
# random sample 
sample_n(weather_tpa, 4)
```

See https://www.reisanar.com/slides/relationships-models#10 for a reminder on how to use this dataset with the `lubridate` package for dates and times.


(a) Recreate the plot below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_facet.png")
```

Hint: the option `binwidth = 3` was used with the `geom_histogram()` function.

```{r}
weather_tpa %>% 
  group_by(month, day) %>% 
  summarise()
```


(b) Recreate the plot below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density.png")
```

Hint: check the `kernel` parameter of the `geom_density()` function, and use `bw = 0.5`.

(c) Recreate the chart below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_density_facet.png")
```

Hint: default options for `geom_density()` were used. 

(d) Recreate the chart below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges.png")
```

Hint: default options for `geom_density()` were used. 

(e) Recreate the plot below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges.png")
```

Hint: use the`ggridges` package, and the `geom_density_ridges()` function paying close attention to the `quantile_lines` and `quantiles` parameters.

(f) Recreate the chart below:

```{r, echo = FALSE, out.width="80%", fig.align='center'}
knitr::include_graphics("https://github.com/reisanar/figs/raw/master/tpa_max_temps_ridges_plasma.png")
```

Hint: this uses the `plasma` option (color scale) for the _viridis_ palette.




## Part 2: Visualizing Text Data

Review the set of slides (and additional resources linked in it) for visualizing text data: https://www.reisanar.com/slides/text-viz#1

Choose any dataset with text data, and create at least one visualization with it. For example, you can create a frequency count of most used bigrams, a sentiment analysis of the text data, a network visualization of terms commonly used together, and/or a visualization of a topic modeling approach to the problem of identifying words/documents associated to different topics in the text data you decide to use. 

Make sure to include a copy of the dataset in the `data/` folder, and reference your sources if different from the ones listed below:

- [Billboard Top 100 Lyrics](https://github.com/reisanar/datasets/blob/master/BB_top100_2015.csv)

- [RateMyProfessors comments](https://github.com/reisanar/datasets/blob/master/rmp_wit_comments.csv)

- [FL Poly News 2020](https://github.com/reisanar/datasets/blob/master/poly_news_FL20.csv)

- [FL Poly News 2019](https://github.com/reisanar/datasets/blob/master/poly_news_FL19.csv)

(to get the "raw" data from any of the links listed above, simply click on the `raw` button of the GitHub page and copy the URL to be able to read it in your computer using the `read_csv()` function)

```{r}
library(tidyverse)
library(tidytext)
```

```{r}
top100 <- read_csv("../data/BB_top100_2015.csv")
```

```{r}
weeknd <- top100 %>% filter(Artist == "the weeknd")
weeknd <- weeknd %>% mutate(
  Song = factor(Song)) 
weeknd
```

```{r}
weeknd_sentiment <- weeknd %>% 
  unnest_tokens(word, Lyrics) %>%
  group_by(Song) %>% 
  mutate(word_count = 1:n(),
         index = word_count %/% 25 + 1) %>% 
  inner_join(get_sentiments("bing")) %>%
  count(Song, index = index, sentiment) %>% 
  pivot_wider(names_from = sentiment, values_from = n)

weeknd_sentiment[is.na(weeknd_sentiment)] <- 0

weeknd_sentiment <- weeknd_sentiment %>% 
  mutate(net_sentiment = positive - negative)
```


```{r}
ggplot(weeknd_sentiment, 
       aes(x = index, y = net_sentiment, fill = net_sentiment > 0)) +
  geom_col() +
  guides(fill = FALSE) +
  labs(x = NULL, y = "Net sentiment") +
  scale_fill_manual(name = "", labels = c("Positive", "Negative"),
                     values = c("#FF851B", "#3D9970")) +
  facet_wrap(vars(Song), scales = "free_x") +
  theme_minimal() +
  labs(title = "The Weeknd Sentiment Analysis")
```

```{r}
drake <- top100 %>% filter(Artist == "drake")
drake <- drake %>% mutate(
  Song = factor(Song)) 
drake
```

```{r}
drake_sentiment <- drake %>% 
  unnest_tokens(word, Lyrics) %>%
  group_by(Song) %>% 
  mutate(word_count = 1:n(),
         index = word_count %/% 25 + 1) %>% 
  inner_join(get_sentiments("bing")) %>%
  count(Song, index = index, sentiment) %>% 
  pivot_wider(names_from = sentiment, values_from = n)

drake_sentiment[is.na(drake_sentiment)] <- 0

drake_sentiment <- drake_sentiment %>% 
  mutate(net_sentiment = positive - negative)
```


```{r}
ggplot(drake_sentiment, 
       aes(x = index, y = net_sentiment, fill = net_sentiment > 0)) +
  geom_col() +
  guides(fill = FALSE) +
  labs(x = NULL, y = "Net sentiment") +
  scale_fill_manual(name = "", labels = c("Positive", "Negative"),
                     values = c("#FF851B", "#3D9970")) +
  facet_wrap(vars(Song), scales = "free_x") +
  theme_minimal() +
  labs(title = "Drake Sentiment Analysis")
```

